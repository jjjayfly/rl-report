% Chapter 5

\chapter{Conclusion and Future Directions} % Main chapter title

\label{Chapter4} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%----------------------------------------------------------------------------------------

\section{Conclusion}
So far, this project shows that given a rule set of reward and penalty, RL algorithms could work well on car self-driving tasks, no matter how the environment is. And we hope this could be a base for future self-driving cars coming into real life and even VR+AI driving school in the Hong Kong market.

\section{Future Works}
Up to now, due to time and computational resource limitations, this project has several shortcomings that can be improved:
\begin{itemize}
\item Because we need more than 2 days to train a single test, so we don't have enough time to train various RL algorithms and make further comparisons(PPO was done, but SAC is still in progress).
\item There is only one agent(i.e., the car) in the driving environment. In the future, we hope to add more agents to co-operate in the simulated world. For example, at present, all the red balls are defined by a uniform random function, which we hope can replace by pedestrian agents.
\item As for environmental construction, we think we can do more exquisitely to be closer to the real-world layout.
\end{itemize}